{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from keplergl import KeplerGl\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import h3\n",
    "from shapely.geometry import shape, Point\n",
    "from turfpy.transformation import convex\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inrix weekday-codes\n",
    "dow_dict = {'Montag':0, 'Dienstag':1, 'Mittwoch':2, 'Donnerstag':3, 'Freitag':4, 'Samstag':5, 'Sonntag':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_0 = os.listdir('./data/FCD/')\n",
    "dates = list(set([x.split('_')[0] for x in files_0]))\n",
    "dates.sort()\n",
    "\n",
    "# define grid size, for more information see: https://h3geo.org/docs/core-library/restable\n",
    "APERTURE_SIZE = 11 # Average edge length: 0.028663897 km\n",
    "hex_col = 'hex'+str(APERTURE_SIZE)\n",
    "\n",
    "plz = pd.read_json('data/Forchheim_plz.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for specific weekdays\n",
    "def check_dates(dates,date_filter):\n",
    "    date_query = []\n",
    "    date_filter = [dow_dict[x] for x in date_filter]\n",
    "\n",
    "    for date in dates:\n",
    "        dow = datetime(int(date[:4]),int(date[4:6]),int(date[6:])).weekday()\n",
    "        if dow in date_filter:\n",
    "            date_query.append(date)\n",
    "        else:\n",
    "            pass\n",
    "    return date_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for specific times\n",
    "def time_filter(df,start,end):\n",
    "    df['hour'] = df['timestamp'].apply(lambda x: x.hour)\n",
    "    df = df[(df['hour'] >= start) & (df['hour']<end)]\n",
    "    df = df.drop(['hour'],axis=1)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and concat all files per day\n",
    "def day_load(date):\n",
    "    date_list = [s for s in files_0 if date in s]\n",
    "    df = pd.read_csv('data/FCD/' + date_list[1], compression='gzip', header=None, sep=',')\n",
    "    headers = ['session_id', 'speed', 'timestamp', 'latitude', 'longitude', 'direction']\n",
    "    df.columns = headers\n",
    "    for i in range(1,len(date_list)):\n",
    "        df_i = pd.read_csv('data/FCD/' + date_list[i], compression='gzip', header=None, sep=',')\n",
    "        headers = ['session_id', 'speed', 'timestamp', 'latitude', 'longitude', 'direction']\n",
    "        df_i.columns = headers\n",
    "        df = pd.concat([df,df_i], axis=0, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon_check(lon, lat):\n",
    "    polygon = shape(plz['geometry'][0]['geometry'])\n",
    "    point = Point(lon, lat)\n",
    "    return polygon.contains(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter trips by location\n",
    "def plz_filter(df,plz):\n",
    "    lng_min, lng_max, lat_min, lat_max = 100, 0, 100, 0\n",
    "    plz_shape = plz['geometry'][0]['geometry']['coordinates'][0]\n",
    "    for i in plz_shape:\n",
    "        if i[0] < lng_min:\n",
    "            lng_min = i[0]\n",
    "        elif i[0] > lng_max:\n",
    "            lng_max = i[0]\n",
    "        else:\n",
    "            pass\n",
    "        if i[1] < lat_min:\n",
    "            lat_min = i[1]\n",
    "        elif i[1] > lat_max:\n",
    "            lat_max = i[1]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    df_plz = df[df['longitude'] > lng_min]\n",
    "    df_plz = df_plz[df_plz['longitude'] < lng_max]\n",
    "    df_plz = df_plz[df_plz['latitude'] > lat_min]\n",
    "    df_plz = df_plz[df_plz['latitude'] < lat_max]\n",
    "\n",
    "    df_plz['Forchheim'] = df_plz.apply(lambda x: polygon_check(x['longitude'], x['latitude']), axis=1)\n",
    "    df_plz = df_plz[df_plz['Forchheim']]\n",
    "    try:\n",
    "        df_plz.drop(['Forchheim'], axis=1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    return df_plz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... the actual grid mapping\n",
    "def h3_mapping(df, hex_col, cutoff):\n",
    "\n",
    "    df[hex_col] = df.apply(lambda x: h3.geo_to_h3(x.latitude,x.longitude,APERTURE_SIZE),1)\n",
    "\n",
    "    df_speed = df.groupby(hex_col)['speed'].mean().to_frame('speed').reset_index()\n",
    "    df_count = df.groupby(hex_col).size().to_frame('count').reset_index()\n",
    "\n",
    "    #df_hex['count'] = df.groupby(hex_col).size().to_frame('count').reset_index()['count']\n",
    "    df_hex = pd.merge(df_speed,df_count,on=hex_col)\n",
    "    df_hex['speed'] = df_hex['speed'].apply(lambda x: round(x,1))\n",
    "\n",
    "    df_hex = df_hex[df_hex['count'] >= cutoff].reset_index(drop=True)\n",
    "\n",
    "    #df_hex = df.groupby(hex_col)['speed'].mean().to_frame('speed').reset_index()\n",
    "    return df_hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "def data_transform(date_query,time_range,cutoff=0):\n",
    "    hex_gesamt = pd.DataFrame([])\n",
    "    dataframes = {}\n",
    "    for i in range(len(time_range)-1):\n",
    "        dataframes['hex_'+str(i)] = pd.DataFrame([])\n",
    "\n",
    "    for date in date_query:\n",
    "        df = day_load(date)\n",
    "        \n",
    "        df['timestamp'] = df['timestamp'].apply(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ'))\n",
    "        df['unix'] = df['timestamp'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "\n",
    "        try:\n",
    "            df = plz_filter(df,plz)\n",
    "            df = df.sort_values(['session_id', 'unix'])\n",
    "            df = df.drop_duplicates(['session_id', 'latitude', 'longitude', 'direction'])\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            df_hex_i = h3_mapping(df, hex_col, cutoff)\n",
    "            hex_gesamt = pd.concat([hex_gesamt, df_hex_i], ignore_index=True)\n",
    "\n",
    "            for i in range(len(time_range)-1):\n",
    "                start = time_range[i]\n",
    "                end = time_range[i+1]\n",
    "                df_i = time_filter(df,start,end)\n",
    "                df_hex_i = h3_mapping(df_i, hex_col, cutoff)\n",
    "                dataframes['hex_'+str(i)] = pd.concat([dataframes['hex_'+str(i)], df_hex_i], ignore_index=True)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        #df_hex = df_hex.groupby(hex_col).mean().reset_index()\n",
    "\n",
    "    speed_df = hex_gesamt.groupby(hex_col)['speed'].mean().reset_index()\n",
    "    count_df = hex_gesamt.groupby(hex_col)['count'].sum().reset_index()\n",
    "    hex_gesamt = pd.merge(speed_df,count_df,on=hex_col)\n",
    "\n",
    "    for i in range(len(time_range)-1):\n",
    "        speed_df = dataframes['hex_'+str(i)].groupby(hex_col)['speed'].mean().reset_index()\n",
    "        count_df = dataframes['hex_'+str(i)].groupby(hex_col)['count'].sum().reset_index()\n",
    "        dataframes['hex_'+str(i)] = pd.merge(speed_df,count_df,on=hex_col)\n",
    "    #df_hex['speed'] = df_hex['speed'].apply(lambda x: round(x,1))\n",
    "\n",
    "    #df_hex = df_hex[df_hex['count'] >= cutoff].reset_index(drop=True)\n",
    "    return hex_gesamt, dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cutoff value specifies the minimum data count per cell\n",
    "cutoff = 20\n",
    "\n",
    "# time slices for detailed analysis. Each slice includes times between the n and n+1 list entry.\n",
    "#time_range = [0,6,10,15,19,24]\n",
    "time_range = [0,12,24]\n",
    "\n",
    "date_filter = ['Montag', 'Dienstag', 'Mittwoch', 'Donnerstag', 'Freitag']\n",
    "date_query = check_dates(dates,date_filter)\n",
    "\n",
    "weekday, weekday_times = data_transform(date_query,time_range,cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "weekday.to_csv('data_export/full_day.csv')\n",
    "df_names = list(weekday_times.keys())\n",
    "for df_name in df_names:\n",
    "    df_i = weekday_times[df_name]\n",
    "    df_i.to_csv('data_export/timeslice_'+ df_name +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
